###########################################################################
## 1.  SVM

from sklearn import svm

X = [[0, 0], [1, 1]]
y = [0, 1]
clf = svm.SVC(gamma='scale')
clf.fit(X, y)
clf.predict([[2., 2.]])


Exemples :

  https://scikit-learn.org/stable/auto_examples/svm/plot_iris_svc.html

  https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html

  https://scikit-learn.org/stable/auto_examples/svm/plot_svm_nonlinear.html

(À noter que le code (py ou ipynb) est téléchargeable en bas de la page.)


###########################################################################
## 2.  Grid search

Afin de trouver les meilleurs hyperparamètres, il existe GridSearchCV().

    from sklearn import svm, datasets
    from sklearn.model_selection import GridSearchCV
    iris = datasets.load_iris()
    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}
    svc = svm.SVC(gamma="scale")
    clf = GridSearchCV(svc, parameters, cv=5)
    clf.fit(iris.data, iris.target)

    sorted(clf.cv_results_.keys())


Et puis, regardez clf.cv_results_

À noter que maintenant il faut faire un train-test-validation split !

Voir aussi  https://scikit-learn.org/stable/modules/grid_search.html .


###########################################################################
## 3.  Évaluation

Plus sur l'évaluation des résultats d'une classification :

    from sklearn.metrics import classification_report, confusion_matrix

    print(confusion_matrix(y_test,y_pred))
    print(classification_report(y_test,y_pred))


Il existe également la validation croisée.

    https://scikit-learn.org/stable/modules/cross_validation.html


###########################################################################
## 4.  Exemple de régression linéaire

import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

# Load the diabetes dataset
diabetes = datasets.load_diabetes()

# Use only one feature
diabetes_X = diabetes.data[:, np.newaxis, 2]

# Split the data into training/testing sets
diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test = \
    train_test_split(diabetes_X, diabetes.target, test_size=.3, random_state=42)

# Create linear regression object
regr = linear_model.LinearRegression()

# Train the model using the training sets
regr.fit(diabetes_X_train, diabetes_y_train)

# Make predictions using the testing set
diabetes_y_pred = regr.predict(diabetes_X_test)

# The coefficients
print('Coefficients: \n', regr.coef_)
# The mean squared error
print("Mean squared error: %.2f"
      % mean_squared_error(diabetes_y_test, diabetes_y_pred))
# Explained variance score: 1 is perfect prediction
print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))

# Plot outputs
plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')
plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)

plt.xticks(())
plt.yticks(())

plt.show()


## Exercice : faire la même chose avec validation croisée.


